When streaming large or continuous data over gRPC, backpressure and flow control help avoid overwhelming the client, wasting memory, or crashing due to fast producers.

  

 ðŸ”„ What is Backpressure?

> Backpressure is the mechanism where the receiver tells the sender to slow down based on its current processing capacity.

Think of a water pipe â€” if the end is clogged, water starts to back up. Similarly, if the client canâ€™t process fast enough, the server must slow down or buffer.

  

 ðŸ”§ How gRPC Handles Flow Control

   gRPC streaming over HTTP/2 inherently supports flow control
   The receiverâ€™s TCP window size limits how much the sender can push
   gRPC client doesnâ€™t pull more data unless stream.Recv() is called (i.e., pull-based)

  

 ðŸ“¦ Server-Side: Implementing Respectful Flow Control

    func (s SensorDataServer) StreamSensorData(req pb.SensorRequest, stream pb.SensorDataStreamSensorDataServer) error {
        ticker := time.NewTicker(time.Second) // simulate data every 1 sec
        defer ticker.Stop()
    
        for {
            select {
            case <-stream.Context().Done(): // client disconnected
                return stream.Context().Err()
            case <-ticker.C:
                err := stream.Send(&pb.SensorReading{
                    Timestamp: timestamppb.Now(),
                    Value:     rand.Float64()  100,
                })
                if err != nil {
                    return err // client might be slow or disconnected
                }
            }
        }
    }
    

  

 ðŸ§  Client-Side: Natural Backpressure via stream.Recv()

    stream,  := client.StreamSensorData(ctx, &pb.SensorRequest{})
    
    for {
        reading, err := stream.Recv() // pull-based â€“ if slow, server waits
        if err == io.EOF {
            break
        }
        process(reading)
        time.Sleep(2  time.Second) // simulate slow consumer
    }
    

 âœ… Because the client reads slowly, the serverâ€™s stream.Send() call blocks until the client pulls the next message.

  

 ðŸ“Š Visual â€“ Pull-Based Flow Control

    Client                          Server
     Recv() <---------------------- Send()
            <--delay 2s--          [Waits]
     Recv() <---------------------- Send()
            <--delay 2s--          [Waits]
    

  

 ðŸ›‘ Problems Without Backpressure

   High memory usage on server (buffered messages)
   Client timeouts or dropped connections
   Lost data due to overflows or packet drops

  

 ðŸ›  Techniques to Improve Flow Control

Technique

Use Case

Context cancellation

Detect client disconnects (via ctx.Done())

Channel buffering + select

Control pace manually on producer side

Limit goroutines

Avoid thousands of unbounded senders

Window-based protocols

Custom throttling based on ACKs or credits

  

 ðŸ§ª Example: Bounded Buffer with Channel for Controlled Pacing

    dataChan := make(chan pb.SensorReading, 10) // bounded buffer
    
    // producer goroutine
    go func() {
        for {
            data := generateSensorData()
            dataChan <- data // blocks if buffer full
        }
    }()
    
    // consumer (gRPC server handler)
    for data := range dataChan {
        if err := stream.Send(data); err != nil {
            break
        }
    }
    

This ensures natural backpressure â€” if the client is slow, the server slows down too.
